{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy pandas pandas_datareader matplotlib yfinance scikit-learn xgboost tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stat data analyzing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas_datareader import data as pdata\n",
    "from datetime import datetime as dtim, timedelta as tdel\n",
    "\n",
    "# projecting data libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# financial data libraries\n",
    "import yfinance as yf\n",
    "\n",
    "# ML libraries\n",
    "import mlflow as mlf\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler as ssc\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error as mse,\n",
    "    mean_absolute_error as mae,\n",
    "    r2_score as r2s,\n",
    ")\n",
    "from tensorflow.keras.models import Sequential as seqMD\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout as dpMD\n",
    "\n",
    "# other miscellaneous libraries\n",
    "import json\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Intake & Refine Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPipeline:\n",
    "\n",
    "    # Constructor for pipeline.\n",
    "    def __init__(self, asset, trading_day_window=30, active_total_trading_days=252):\n",
    "        self.asset = asset\n",
    "        self.trading_window = trading_day_window\n",
    "        self.active_days = active_total_trading_days\n",
    "        self.scaling_factor = np.sqrt(active_total_trading_days)\n",
    "        self.dataframe = None\n",
    "        self.features = None\n",
    "        self.scaled_features = None\n",
    "\n",
    "    ## Fetching past for the asset for this interval of time.\n",
    "    def fetch_financial_data(self, start_date, end_date):\n",
    "\n",
    "        # this dataframe holds OHLCV data. (Open, HIgh, Low, Close, Volume).\n",
    "        dataframe = yf.download(tickers=self.asset, start=start_date, end=end_date)\n",
    "\n",
    "        ## Calculating returns.\n",
    "        dataframe[\"Returns\"] = np.log(dataframe[\"Close\"] / dataframe[\"Close\"].shift(1))\n",
    "\n",
    "        ## Returning the dataframe with returns calculated.\n",
    "        self.dataframe = dataframe\n",
    "        return dataframe\n",
    "\n",
    "    ## Calculating Realized Volatility -> Standard Deviation of Returns from the Mean Return.\n",
    "    def calculate_realized_volatility(self):\n",
    "        # taken a month by default can change it accordingly.\n",
    "\n",
    "        ## Calculating the Annual Volatility using the Rolling Window Standard Deviation and Scaling it.\n",
    "        self.dataframe[\"RealizedVolatility\"] = (\n",
    "            self.dataframe[\"Returns\"].rolling(window=self.trading_window).std()\n",
    "        ) * (self.scaling_factor)\n",
    "\n",
    "        ## Calculating High-Low Volatility\n",
    "        self.dataframe[\"HighLowVolatility\"] = np.log(\n",
    "            self.dataframe[\"High\"] / self.dataframe[\"Low\"]\n",
    "        )\n",
    "\n",
    "        ## Calculating GARMAN KLASS Volatility using the mathematical formula\n",
    "        self.dataframe[\"GarmanKlassVolatility\"] = np.sqrt(\n",
    "            (((np.log(self.dataframe[\"High\"] / self.dataframe[\"Low\"])) ** 2) * 0.5)\n",
    "            - (\n",
    "                ((2 * (np.log(2))) - 1)\n",
    "                * ((np.log(self.dataframe[\"Close\"] / self.dataframe[\"Open\"])) ** 2)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return self.dataframe\n",
    "\n",
    "    ## Technical Indicators and features for Volatility Prediction\n",
    "    def create_feature_set(self, Moving_AvgStd_window=22, lookback_period=[5, 10, 22]):\n",
    "\n",
    "        # Ensuring the returns are present\n",
    "        if \"Returns\" not in self.dataframe.columns:\n",
    "            self.dataframe[\"Returns\"] = np.log(\n",
    "                self.dataframe[\"Close\"] / self.dataframe[\"Close\"].shift(1)\n",
    "            )\n",
    "\n",
    "        ## Calculating features\n",
    "        if self.features is None:\n",
    "            self.features = pd.DataFrame(index=self.dataframe.index)\n",
    "\n",
    "        ### Volume-based features\n",
    "        #### this is the rolling mean\n",
    "        self.features[\"Volume_MovAvg\"] = (\n",
    "            self.dataframe[\"Volume\"].rolling(window=Moving_AvgStd_window).mean()\n",
    "        )\n",
    "        #### this is the rolling standard deviation\n",
    "        self.features[\"Volume_StdDev\"] = (\n",
    "            self.dataframe[\"Volume\"].rolling(window=Moving_AvgStd_window).std()\n",
    "        )\n",
    "\n",
    "        ### Price-based features\n",
    "        for period in lookback_period:\n",
    "\n",
    "            #### Moving avgs\n",
    "            self.features[f\"Price_MovAvg_{period}\"] = (\n",
    "                self.dataframe[\"Close\"].rolling(window=period).mean()\n",
    "            )\n",
    "            self.features[f\"Price_StdDev_{period}\"] = (\n",
    "                self.dataframe[\"Close\"].rolling(window=period).std()\n",
    "            )\n",
    "\n",
    "            #### RSI -> Relative Strength Index ==> OverBought or OverSold\n",
    "            delta = self.dataframe[\"Close\"].diff()\n",
    "            avg_gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
    "            ##### if the where condition is not satisfied then we replace it by 0\n",
    "            avg_loss = (delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
    "            relative_strength = avg_gain / avg_loss\n",
    "            self.features[f\"RSI_{period}\"] = 100 - (100 / (1 + relative_strength))\n",
    "\n",
    "            #### Historical Volatility\n",
    "            self.features[f\"Hist_Vol_{period}\"] = (\n",
    "                self.dataframe[\"Returns\"].rolling(window=period).std()\n",
    "            ) * self.scaling_factor\n",
    "\n",
    "        ### VWAP-> Volume Weighted Average Price\n",
    "        self.features[\"VWAP\"] = (\n",
    "            self.dataframe[\"Close\"] * self.dataframe[\"Volume\"]\n",
    "        ).cumsum()\n",
    "\n",
    "        return self.features\n",
    "\n",
    "    ## Preparing complete dataset for the training volatility predictor model\n",
    "    def prepare_training_data(\n",
    "        self,\n",
    "        start_date,\n",
    "        end_date,\n",
    "        Moving_AvgStd_window=22,\n",
    "        lookback_period=[5, 10, 22],\n",
    "        prediction_horizon=5,\n",
    "    ):\n",
    "        self.fetch_financial_data(start_date, end_date)\n",
    "        self.calculate_realized_volatility()\n",
    "        self.create_feature_set(Moving_AvgStd_window, lookback_period)\n",
    "\n",
    "        # Target variable -> Future Volatility\n",
    "        target = self.dataframe[\"RealizedVolatility\"].shift(-(prediction_horizon))\n",
    "\n",
    "        # Combining features and target\n",
    "        final_dataset = pd.concat(\n",
    "            [features, target], axis=1\n",
    "        ).dropna()  #### dropping the columns with missing values from the data set\n",
    "\n",
    "        # Getting the feature names before scaling\n",
    "        feature_cols = final_dataset.columns[:1]  ### all columns except the target\n",
    "\n",
    "        ### starting the standard scaler\n",
    "        scaler = ssc()\n",
    "\n",
    "        # Fit and transform the features (target not included)\n",
    "        scaled_features = scaler.fit_transform(final_dataset.iloc[:, :-1])\n",
    "\n",
    "        ## Convert scaled features back to dataframe with correct column names\n",
    "        self.scaled_features_df = pd.DataFrame(\n",
    "            scaled_features, index=final_dataset.index, columns=feature_cols\n",
    "        )\n",
    "\n",
    "        return final_dataset[\"RealizedVolatility\"], scaler"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mini_conda_envs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
